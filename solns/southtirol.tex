\documentclass[10pt]{amsart}
%prepared in AMSLaTeX, under LaTeX2e
\addtolength{\oddsidemargin}{-.7in}
\addtolength{\evensidemargin}{-.7in}
\addtolength{\topmargin}{-.4in}
\addtolength{\textwidth}{1.3in}
\addtolength{\textheight}{1.0in}

\newcommand{\normalspacing}{\renewcommand{\baselinestretch}{1.05}
        \tiny\normalsize}

\usepackage{amssymb,fancyvrb,alltt,xspace}

\VerbatimFootnotes

\usepackage{fancyvrb}
\newcommand{\mfile}[1]{
\begin{quote}
\bigskip
%\VerbatimInput[frame=single]{#1}
\VerbatimInput[frame=single,label=\fbox{\normalsize \textsl{\,#1\,}},fontfamily=courier,fontsize=\small]{#1}
\end{quote}
}


% macros
\newcommand{\CC}{\mathbb{C}}
\newcommand{\Div}{\nabla\cdot}
\newcommand{\eps}{\epsilon}
\newcommand{\grad}{\nabla}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\ip}[2]{\ensuremath{\left<#1,#2\right>}}
\newcommand{\lam}{\lambda}
\newcommand{\lap}{\triangle}
\newcommand{\RR}{\mathbb{R}}

\newcommand{\prob}[1]{\bigskip\noindent\large\textbf{#1.}\normalsize }
\newcommand{\apart}[1]{\quad \textbf{(#1)} \quad }
\newcommand{\ppart}[1]{\medskip\noindent\textbf{(#1)} \quad }

\newcommand{\Matlab}{\textsc{Matlab}\xspace}
\newcommand{\Octave}{\textsc{Octave}\xspace}


\begin{document}
\Large\centerline{\textbf{Solutions}}

\medskip
\small
\centerline{\emph{These are reasonably complete solutions to some notes available at a small town in the Schnalstal valley.}}
\normalsize

\bigskip\bigskip

\thispagestyle{empty}
\normalspacing

\prob{1}  Start with two Taylor expansions around $x$:
    $$f(x\pm \Delta) = f(x) \pm f'(x) \Delta + \frac{1}{2} f''(x) \Delta^2 \pm \frac{1}{6} f'''(x) \Delta^3 + \dots$$
Subtracting the two:
    $$f(x+\Delta) - f(x-\Delta) = 2 f'(x) \Delta + \frac{1}{3} f'''(x) \Delta^3 + \dots$$
Solve for $f'(x)$:
    $$f'(x) = \frac{f(x+\Delta) - f(x-\Delta)}{2\Delta} - \frac{1}{6} f'''(x) \Delta^2 + \dots$$
This shows the first result.  For the second we expand to one more term and do the same basic steps, starting with adding the two expansions and then solving for $f''(x)$:
\begin{gather*}
    f(x\pm \Delta) = f(x) \pm f'(x) \Delta + \frac{1}{2} f''(x) \Delta^2 \pm \frac{1}{6} f'''(x) \Delta^3 + \frac{1}{24} f^{(4)}(x) \Delta^4 + \dots \\
    f(x + \Delta) + f(x - \Delta) = 2 f(x) + f''(x) \Delta^2 + \frac{1}{12} f^{(4)}(x) \Delta^4 + \dots \\
    f''(x) = \frac{f(x + \Delta) - 2 f(x) + f(x - \Delta)}{\Delta^2} - \frac{1}{12} f^{(4)}(x) \Delta^2 + \dots
\end{gather*}
This shows the second result.

\prob{2}  In problem \textbf{1} we had $x$ as base-point and we moved $\Delta$ to left and right.  Now we use $x+\Delta/2$ as base-point and move $\Delta/2$ to left and right:
\begin{gather*}
f(x) = f(x+\Delta/2) - \frac{1}{2} f'(x+\Delta/2) \Delta + \frac{1}{8} f''(x+\Delta/2) \Delta^2 - \frac{1}{48} f'''(x+\Delta/2) \Delta^3 + \dots \\
f(x+\Delta) = f(x+\Delta/2) + \frac{1}{2} f'(x+\Delta/2) \Delta + \frac{1}{8} f''(x+\Delta/2) \Delta^2 + \frac{1}{48} f'''(x+\Delta/2) \Delta^3 + \dots
\end{gather*}
Subtracting these and solving for $f'(x+\Delta x/2)$ give, in turn,
\begin{gather*}
f(x+\Delta) - f(x) = f'(x+\Delta/2) \Delta + \frac{1}{24} f'''(x+\Delta/2) \Delta^3 + \dots \\
f'(x+\Delta/2) = \frac{f(x+\Delta) - f(x)}{\Delta} - \frac{1}{24} f'''(x+\Delta/2) \Delta^2 + \dots
\end{gather*}
as desired.

\prob{3}

\mfile{heatwithloops.m}

\prob{4}  If $\Delta t < 0$ then $\mu = D \Delta t / \Delta x^2 < 0$ also.  Then $T_j^{n+1} = \mu T_{j+1}^n + (1 - 2 \mu) T_j^n + \mu T_{j-1}^n$ writes $T_j^{n+1}$ as a linear combination of the three ``old'' values, but with the coefficients of $T_{j+1}^n$ and $T_{j-1}^n$ both negative.  Though the sum of coefficients is still one (i.e.~$\mu + (1-2\mu) + \mu = 1$), this is not an average for any $\Delta t < 0$.

On the other hand, running
\begin{verbatim}
  >> heat(1.0,30,30,-0.001,20);
\end{verbatim}
which goes backward in time from $t=0$ to $t=-0.020$, produces an obviously nonsensical distribution of heat (not shown).

\prob{5}  Rewriting (35) for $T_j^{n+1}$ gives
    $$T_j^{n+1} \stackrel{\ast}{=} T_j^n + \mu T_{j+1}^{n+1} - 2 \mu T_j^{n+1} + \mu T_{j-1}^{n+1}$$
or
    $$T_j^{n+1} = \frac{1}{1 - 2\mu} T_j^n + \frac{\mu}{1 - 2\mu} T_{j+1}^{n+1} + \frac{\mu}{1 - 2\mu} T_{j-1}^{n+1}.$$
In the last form we have written $T_j^{n+1}$ as an average of neighboring points.  That is, the coefficients are positive and add to one.  This allows a ``maximum principle'' proof of unconditional convergence, and thus unconditional stability; see reference [37] (= Morton \& Mayers).

An alternative proof of unconditional stability is via a von Neumann-Fourier argument [37].  For such an argument we look at the evolution of waves on the space-time grid:
    $$T_j^n \stackrel{\dagger}{=} \lambda^n e^{i\omega (j\Delta x)}.$$
We are interested in how the growth/decay rate $\lambda$ depends on the spatial frequency $\omega$.  Numerical stability is the statement ``all waves decay,'' that is, that we can show $|\lambda|<1$ for all $\omega$.  Unconditional numerical stability is when this occurs regardless of the values of $\Delta t$ and $\Delta x$.

In the case of the implicit scheme we are examining, if we start from the first form of the scheme $\ast$ above, and if we substitute \emph{ansatz} $\dagger$ and then cancel as much as possible, we get
    $$\lambda = 1 + \mu \lambda e^{i\omega\Delta x} - 2 \mu \lambda + \mu \lambda e^{-i\omega\Delta x}$$
or
    $$\lambda = 1 - 2 \mu \lambda + 2 \mu \lambda \cos(\omega\Delta x)$$
(by recalling $\cos z = (e^{iz} + e^{-iz}) / 2$) or
    $$\lambda (1 + 2\mu (1 - \cos(\omega\Delta x)) = 1$$
or
    $$\lambda = \frac{1}{1 + 4 \mu \sin^2(\omega\Delta x/2)}$$
(by recalling $2 \sin^2 z = 1-\cos(2z)$).  The point about our final form is that $\lambda > 0$ is obvious \emph{and} $\lambda < 1$ is obvious.  Thus we have shown that our implicit scheme makes all spatial waves (modes) decay, regardless of the value of $\mu$, and thus regardless of the grid spacings $\Delta t$ and $\Delta x$.  This is unconditional stability.

\prob{6}  FIXME

\prob{7}  Suppose $s = t^{-1/2} x$ and $T(t,x)=t^{-1/2} \phi(s)$.  By the chain rule we can write $T_t$ and $T_{xx}$ with a common power of $t$ and otherwise in terms of $s$:
\begin{align*}
T_t &= - \frac{1}{2} t^{-3/2} \phi(s) + t^{-1/2} \phi'(s) \left(-\frac{1}{2}\right) t^{-3/2} x = - \frac{1}{2} t^{-3/2} \phi(s) - \frac{1}{2} t^{-3/2} s \phi'(s), \\
T_x &= t^{-1/2} \phi'(s) t^{-1/2} = t^{-1} \phi'(s), \\
T_{xx} &= t^{-1} \phi''(s) t^{-1/2} = t^{-3/2} \phi''(s),
\end{align*}
where a prime denotes derivative with respect to $s$.  Thus $T_t = D T_{xx}$ is equivalent to
    $$- \frac{1}{2} t^{-3/2} \phi(s) - \frac{1}{2} t^{-3/2} s \phi'(s) = D t^{-3/2} \phi''(s).$$

Cancelling the common power of $t$ gives a second-order ODE in $s$ for $\phi(s)$:
    $$- \frac{1}{2} \left[\phi(s) + s \phi'(s)\right] = D \phi''(s).$$
But this can be solved because the left side is a derivative, namely $\phi(s) + s \phi'(s) = \left(s \phi(s)\right)'$, so the second-order ODE is $- \frac{1}{2} \left(s \phi(s)\right)' = D \phi''(s)$ or
    $$- \frac{1}{2} s \phi(s) = D \phi'(s) + C_0$$
for some constant $C_0$.  Setting $s=0$ and noting that smoothness requires zero slope at the origin (i.e.~$\phi'(0)=0$) so $C_0=0$.  Now we have a first-order ODE which is separable
    $$- \frac{1}{2D} s \,ds = \frac{d\phi}{\phi}.$$
Its integral gives
    $$- \frac{1}{4D} s^2 + C_1 = \ln|\phi|$$
or, after exponentiating,
    $$\phi(s) = A e^{- s^2/(4D)}$$
for some constant $A = \pm e^{C_1}$.

At this point we have our similarity solution, though with an unknown constant:
    $$T(t,x) = t^{-1/2} \phi(s) = A t^{-1/2} e^{- x^2/(4Dt)}.$$
The constant must be set, whatever the details, by the fact that the initial condition is a \emph{unit} amount of heat: $T(0,x) = \delta(x)$, the Dirac delta function with $\int_{-\infty}^\infty \delta(x)\,dx = 1$.  One way to use this information is to note that the heat equation is the conservation of energy equation, so the total heat energy $\int_{-\infty}^\infty T(t,x)\,dx$ is independent of $t$.  Thus we can set $A$ by noting $T(1,x)$ has the same total energy as the initial amount of heat:
    $$\int_{-\infty}^\infty T(1,x)\,dx = \int_{-\infty}^\infty A e^{- x^2/(4D)}\,dx = 1.$$
Recall, or use a reference to learn that, $\int_{-\infty}^\infty e^{- u^2}\,du = \sqrt{\pi}$.  It follows that
    $$1 = \int_{-\infty}^\infty A e^{- x^2/(4D)}\,dx = A \sqrt{4D} \int_{-\infty}^\infty e^{- u^2}\,du = A \sqrt{4\pi D}$$
by substitution $u=x/\sqrt{4D}$.  Thus $A = (4\pi D)^{-1/2}$ and $T(t,x) = (4\pi D t)^{-1/2} e^{- x^2/(4Dt)}$ as claimed.

\prob{8}  

\prob{9}  

\prob{10}  

\prob{11}  The time-dependent margin radius of the Halfar solution is $R(t) = R_0 (t/t_0)^{1/18}$, an expression which comes from setting $H(t,r)=0$ and solving.  The volume at time $t$ is found by integrating out to this radius.  Using polar coordinates and successive substitutions $s = (t/t_0)^{1/18}$ and then $u=r/(R_0 s)$ we have
\begin{align*}
V(t) &= \int_0^{2\pi} \int_0^{R(t)} H(t,r) \,r\,dr\,d\theta \\
     &= 2\pi \int_0^{R_0 (t/t_0)^{1/18}} H_0 \left(\frac{t_0}{t}\right)^{1/9} \left[1 - \left(\left(\frac{t_0}{t}\right)^{1/18} \frac{r}{R_0}\right)^{4/3}\right]^{3/7} \,r\,dr \\
     &= 2\pi H_0 R_0^2 \int_0^1 \left(1 - u^{4/3}\right)^{3/7} \,u\,du.
\end{align*}
At this point we are done!  The last expression is not known yet,\footnote{The integral can be easily approximated numerically: $\int_0^1 (1 - u^{4/3})^{3/7} \,u\,du \approx 0.31422$.  Thus $V(t) = C H_0 R_0^2$ for a value $C\approx 2$ which can be computed accurately to many digits, if desired.} but it is independent of $t$.
%>> quadl(@(u) u.*(1 - u.^(4/3)).^(3/7),0,1)
%ans =  0.31422
%>> quad(@(u) u.*(1 - u.^(4/3)).^(3/7),0,1)
%ans =  0.31422

\prob{12}  

\prob{13}  

\prob{14}  

\prob{15}  

\prob{16}  

\prob{17}  

\prob{18}  

\end{document}

